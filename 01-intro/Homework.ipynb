{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b43a84ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbe3b4ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16554a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in /home/codespace/anaconda3/lib/python3.9/site-packages (16.1.0)\r\n",
      "Requirement already satisfied: numpy>=1.16.6 in /home/codespace/anaconda3/lib/python3.9/site-packages (from pyarrow) (1.21.5)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1fa838b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jan23 = pd.read_parquet('https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3517e56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feb23 = pd.read_parquet('https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-02.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9e1fb24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3066766, 19)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_jan23.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "113475de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VendorID                     0\n",
      "tpep_pickup_datetime         0\n",
      "tpep_dropoff_datetime        0\n",
      "passenger_count          71743\n",
      "trip_distance                0\n",
      "RatecodeID               71743\n",
      "store_and_fwd_flag       71743\n",
      "PULocationID                 0\n",
      "DOLocationID                 0\n",
      "payment_type                 0\n",
      "fare_amount                  0\n",
      "extra                        0\n",
      "mta_tax                      0\n",
      "tip_amount                   0\n",
      "tolls_amount                 0\n",
      "improvement_surcharge        0\n",
      "total_amount                 0\n",
      "congestion_surcharge     71743\n",
      "airport_fee              71743\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_jan23.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c4df953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VendorID                     0\n",
      "passenger_count          71743\n",
      "trip_distance                0\n",
      "RatecodeID               71743\n",
      "PULocationID                 0\n",
      "DOLocationID                 0\n",
      "payment_type                 0\n",
      "fare_amount                  0\n",
      "extra                        0\n",
      "mta_tax                      0\n",
      "tip_amount                   0\n",
      "tolls_amount                 0\n",
      "improvement_surcharge        0\n",
      "total_amount                 0\n",
      "congestion_surcharge     71743\n",
      "airport_fee              71743\n",
      "dtype: int64\n",
      "VendorID                 True\n",
      "passenger_count          True\n",
      "trip_distance            True\n",
      "RatecodeID               True\n",
      "PULocationID             True\n",
      "DOLocationID             True\n",
      "payment_type             True\n",
      "fare_amount              True\n",
      "extra                    True\n",
      "mta_tax                  True\n",
      "tip_amount               True\n",
      "tolls_amount             True\n",
      "improvement_surcharge    True\n",
      "total_amount             True\n",
      "congestion_surcharge     True\n",
      "airport_fee              True\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "numeric_cols = df_jan23.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "# Check for NaNs in numeric columns\n",
    "print(df_jan23[numeric_cols].isnull().sum())\n",
    "\n",
    "# Replace NaNs with a specific value (e.g., 0)\n",
    "df_jan23[numeric_cols] = df_jan23[numeric_cols].fillna(0)\n",
    "\n",
    "# Check for infinity or excessively large values\n",
    "print(np.isfinite(df_jan23[numeric_cols]).all())\n",
    "\n",
    "# Replace infinities with a specific value (e.g., max finite value)\n",
    "df_jan23[numeric_cols] = df_jan23[numeric_cols].replace([np.inf, -np.inf], 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a52ee3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jan23['tpep_pickup_datetime'] = pd.to_datetime(df_jan23['tpep_pickup_datetime'])\n",
    "df_jan23['tpep_dropoff_datetime'] = pd.to_datetime(df_jan23['tpep_dropoff_datetime'])\n",
    "\n",
    "df_jan23['Trip_Duration'] = (df_jan23['tpep_pickup_datetime'] - df_jan23['tpep_dropoff_datetime']).dt.total_seconds() / 60\n",
    "df_jan23['Trip_Duration'].std()\n",
    "\n",
    "df_jan23['tpep_pickup_datetime'] = pd.to_datetime(df_jan23['tpep_pickup_datetime']).astype(str)\n",
    "df_jan23['tpep_dropoff_datetime'] = pd.to_datetime(df_jan23['tpep_dropoff_datetime']).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01acbadc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.782291834460144e-07\n"
     ]
    }
   ],
   "source": [
    "filtered_df = df_jan23[(df_jan23['Trip_Duration'] >= 1) & (df_jan23['Trip_Duration'] <= 60)]\n",
    "fraction_left = len(filtered_df) / len(df_jan23)\n",
    "print(fraction_left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "348a2be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the location IDs to strings\n",
    "df_jan23['PULocationID'] = df_jan23['PULocationID'].astype(str)\n",
    "df_jan23['DOLocationID'] = df_jan23['DOLocationID'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2444e797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure there are no NaNs or infinite values in the numeric columns\n",
    "df_jan23 = df_jan23.fillna(0)\n",
    "df_jan23 = df_jan23.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "# Work with a smaller subset of the data\n",
    "df_jan23_subset = df_jan23.sample(n=1000, random_state=1)\n",
    "# Turn the DataFrame into a list of dictionaries\n",
    "list_of_dicts = df_jan23_subset.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fda020a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a dictionary vectorizer\n",
    "dv = DictVectorizer(sparse=False)\n",
    "feature_matrix = dv.fit_transform(list_of_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13d31491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names: ['DOLocationID=1' 'DOLocationID=10' 'DOLocationID=100' ...\n",
      " 'tpep_pickup_datetime=2023-01-31 22:01:01'\n",
      " 'tpep_pickup_datetime=2023-01-31 22:04:33' 'trip_distance']\n",
      "Dimensionality (number of columns): 2200\n"
     ]
    }
   ],
   "source": [
    "# Determine the dimensionality of the feature matrix\n",
    "dimensionality = feature_matrix.shape[1]\n",
    "\n",
    "# Display the feature names and the dimensionality\n",
    "print(\"Feature names:\", dv.get_feature_names_out())\n",
    "print(\"Dimensionality (number of columns):\", dimensionality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "554c9377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix size: (1000, 2200)\n",
      "Target variable size: (3066766,)\n",
      "Any NaNs in X_train: False\n",
      "Any NaNs in y_train: False\n",
      "Any infinities in X_train: False\n",
      "Any infinities in y_train: False\n"
     ]
    }
   ],
   "source": [
    "# Check the size of the feature matrix and target variable\n",
    "print(\"Feature matrix size:\", feature_matrix.shape)\n",
    "print(\"Target variable size:\", df_jan23['Trip_Duration'].shape)\n",
    "\n",
    "# Use a much smaller subset of the data for testing\n",
    "subset_size = 1000  # Reduce the subset size for initial testing\n",
    "X_train = feature_matrix[:subset_size]\n",
    "y_train = df_jan23['Trip_Duration'][:subset_size]\n",
    "\n",
    "# Check for any NaNs or infinite values\n",
    "print(\"Any NaNs in X_train:\", np.isnan(X_train).any())\n",
    "print(\"Any NaNs in y_train:\", np.isnan(y_train).any())\n",
    "print(\"Any infinities in X_train:\", np.isinf(X_train).any())\n",
    "print(\"Any infinities in y_train:\", np.isinf(y_train).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdfb2fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize and train a linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the training data\n",
    "y_train_pred = model.predict(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f18bc00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on train: 9.736102724559258e-12\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calculate RMSE on training data\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "\n",
    "print(\"RMSE on train:\", rmse_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b668ea48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413ede9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the training data\n",
    "df_jan23 = preprocess(df_jan23)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eaeea46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert the DataFrame to a list of dictionaries for training data\n",
    "list_of_dicts_train = df_jan23[['PULocationID', 'DOLocationID']].to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7fb8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the DictVectorizer on training data\n",
    "dv = DictVectorizer(sparse=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f638aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix_train = dv.fit_transform(list_of_dicts_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0822deaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "X_train = feature_matrix_train\n",
    "y_train = df_jan23['Trip_Duration']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3d12a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Preprocess the validation data\n",
    "df_feb23 = preprocess(df_feb23)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff8c78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the DataFrame to a list of dictionaries for validation data\n",
    "list_of_dicts_val = df_feb23[['PULocationID', 'DOLocationID']].to_dict(orient='records')\n",
    "\n",
    "# Transform the validation data using the already fitted DictVectorizer\n",
    "feature_matrix_val = dv.transform(list_of_dicts_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5cb887",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b272d074",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
